{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26cd1dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'dd (Python -1.-1.-1)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from myagents.prompts import agent1_prompt,agent2_prompt,agent3_prompt\n",
    "\n",
    "\n",
    "\n",
    "from tools.search_tool import search_content\n",
    "\n",
    "\n",
    "llm=ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "tools = [search_content]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# --- Define Agent 1: Search Agent ---\n",
    "search_agent_prompt = SystemMessage(content=agent1_prompt)\n",
    "def search_agent(state: MessagesState):\n",
    "    return {\"messages\": [llm_with_tools.invoke([search_agent_prompt] + state[\"messages\"])]}\n",
    "\n",
    "# --- Define Agent 2: Content Agent ---\n",
    "content_agent_prompt = SystemMessage(content=agent2_prompt)\n",
    "def content_agent(state: MessagesState):\n",
    "    return {\"messages\": [llm.invoke([content_agent_prompt] + state[\"messages\"])]}\n",
    "\n",
    "# --- Define Agent 3: Tuning Agent ---\n",
    "tune_agent_prompt = SystemMessage(content=agent3_prompt)\n",
    "def tune_agent(state: MessagesState):\n",
    "    return {\"messages\": [llm.invoke([tune_agent_prompt] + state[\"messages\"])]}\n",
    "\n",
    "# --- Build Graph ---\n",
    "graph = StateGraph(MessagesState)\n",
    "\n",
    "graph.add_node(\"search_agent\", search_agent)\n",
    "graph.add_node(\"tools\", ToolNode(tools))\n",
    "graph.add_node(\"content_agent\", content_agent)\n",
    "graph.add_node(\"tune_agent\", tune_agent)\n",
    "\n",
    "\n",
    "#  Use tools_condition to decide when to call the tool\n",
    "graph.add_edge(START,\"search_agent\")\n",
    "graph.add_conditional_edges(\n",
    "    \"search_agent\",\n",
    "    tools_condition,\n",
    "    {\"tools\": \"tools\", \"__end__\": \"content_agent\"}\n",
    ")\n",
    "\n",
    "# After tools run â†’ back to search_agent\n",
    "graph.add_edge(\"tools\", \"search_agent\")\n",
    "\n",
    "graph.add_edge(\"search_agent\",\"content_agent\")\n",
    "\n",
    "graph.add_edge(\"content_agent\",\"tune_agent\")\n",
    "\n",
    "# tune Agent â†’ END\n",
    "graph.add_edge(\"tune_agent\", END)\n",
    "\n",
    "# --- Compile Agent ---\n",
    "agent = graph.compile()\n",
    "agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cfec78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from myagents.prompts import agent1_prompt, agent2_prompt, agent3_prompt\n",
    "\n",
    "\n",
    "from tools.search_tool import search_content\n",
    "\n",
    "# --- Initialize LLM ---\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "# llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "tools = [search_content]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# --- Define Agent 1: Search Agent ---\n",
    "search_agent_prompt = SystemMessage(content=agent1_prompt)\n",
    "def search_agent(state: MessagesState):\n",
    "    return {\"messages\": [llm_with_tools.invoke([search_agent_prompt] + state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# === Specialized Content Agents ===\n",
    "def blog_agent(state: MessagesState):\n",
    "    prompt = SystemMessage(content=f\"{agent2_prompt}\\n\\nInstruction: Write an engaging, SEO-friendly blog post.\")\n",
    "    return {\"messages\": [llm.invoke([prompt] + state[\"messages\"])]}\n",
    "\n",
    "def article_agent(state: MessagesState):\n",
    "    prompt = SystemMessage(content=f\"{agent2_prompt}\\n\\nInstruction: Write a well-researched, formal article.\")\n",
    "    return {\"messages\": [llm.invoke([prompt] + state[\"messages\"])]}\n",
    "\n",
    "def summary_agent(state: MessagesState):\n",
    "    prompt = SystemMessage(content=f\"{agent2_prompt}\\n\\nInstruction: Summarize the topic in concise bullet points.\")\n",
    "    return {\"messages\": [llm.invoke([prompt] + state[\"messages\"])]}\n",
    "\n",
    "def email_agent(state: MessagesState):\n",
    "    prompt = SystemMessage(content=f\"{agent2_prompt}\\n\\nInstruction: Write a professional email draft.\")\n",
    "    return {\"messages\": [llm.invoke([prompt] + state[\"messages\"])]}\n",
    "\n",
    "def script_agent(state: MessagesState):\n",
    "    prompt = SystemMessage(content=f\"{agent2_prompt}\\n\\nInstruction: Create a creative video or podcast script.\")\n",
    "    return {\"messages\": [llm.invoke([prompt] + state[\"messages\"])]}\n",
    "\n",
    "def social_agent(state: MessagesState):\n",
    "    prompt = SystemMessage(content=f\"{agent2_prompt}\\n\\nInstruction: Write a catchy social media caption or post.\")\n",
    "    return {\"messages\": [llm.invoke([prompt] + state[\"messages\"])]}\n",
    "\n",
    "def general_agent(state: MessagesState):\n",
    "    prompt = SystemMessage(content=f\"{agent2_prompt}\\n\\nInstruction: Write a detailed explanation.\")\n",
    "    return {\"messages\": [llm.invoke([prompt] + state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# --- Define Tuning Agent ---\n",
    "tune_agent_prompt = SystemMessage(content=agent3_prompt)\n",
    "def tune_agent(state: MessagesState):\n",
    "    return {\"messages\": [llm.invoke([tune_agent_prompt] + state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# --- Helper Function: Decide Which Agent to Use ---\n",
    "def select_content_agent(state: MessagesState):\n",
    "    \"\"\"\n",
    "    Decide which content agent to use based on `content_type` inside the user's message.\n",
    "    \"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    content_type = None\n",
    "\n",
    "    for msg in messages:\n",
    "        if isinstance(msg, HumanMessage) and isinstance(msg.content, dict):\n",
    "            content_type = msg.content.get(\"content_type\", \"\").lower()\n",
    "            break\n",
    "\n",
    "    mapping = {\n",
    "        \"blog\": \"blog_agent\",\n",
    "        \"article\": \"article_agent\",\n",
    "        \"summary\": \"summary_agent\",\n",
    "        \"email\": \"email_agent\",\n",
    "        \"script\": \"script_agent\",\n",
    "        \"social\": \"social_agent\",\n",
    "    }\n",
    "\n",
    "    # Default to general_agent if not found\n",
    "    return mapping.get(content_type, \"general_agent\")\n",
    "\n",
    "\n",
    "# --- Build Graph ---\n",
    "graph = StateGraph(MessagesState)\n",
    "graph.add_node(\"search_agent\", search_agent)\n",
    "graph.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "# Add all specialized content agents\n",
    "graph.add_node(\"blog_agent\", blog_agent)\n",
    "graph.add_node(\"article_agent\", article_agent)\n",
    "graph.add_node(\"summary_agent\", summary_agent)\n",
    "graph.add_node(\"email_agent\", email_agent)\n",
    "graph.add_node(\"script_agent\", script_agent)\n",
    "graph.add_node(\"social_agent\", social_agent)\n",
    "graph.add_node(\"general_agent\", general_agent)\n",
    "\n",
    "graph.add_node(\"tune_agent\", tune_agent)\n",
    "\n",
    "# --- Graph Connections ---\n",
    "graph.add_edge(START, \"search_agent\")\n",
    "\n",
    "# Conditional path after search\n",
    "graph.add_conditional_edges(\"search_agent\", tools_condition, {\"tools\": \"tools\", \"__end__\": select_content_agent})\n",
    "graph.add_edge(\"tools\", \"search_agent\")\n",
    "\n",
    "# After chosen content agent â†’ tuning â†’ END\n",
    "for node in [\"blog_agent\", \"article_agent\", \"summary_agent\", \"email_agent\", \"script_agent\", \"social_agent\", \"general_agent\"]:\n",
    "    graph.add_edge(node, \"tune_agent\")\n",
    "\n",
    "graph.add_edge(\"tune_agent\", END)\n",
    "\n",
    "agent = graph.compile()\n",
    "\n",
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25390737",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "\n",
    "from tools.search_tool import search_content\n",
    "from myagents.prompts import agent1_prompt, agent3_prompt  # removed agent2_prompt\n",
    "\n",
    "# --- Initialize LLM ---\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "# llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "tools = [search_content]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# --- Define Agent 1: Search Agent ---\n",
    "search_agent_prompt = SystemMessage(content=agent1_prompt)\n",
    "def search_agent(state: MessagesState):\n",
    "    return {\"messages\": [llm_with_tools.invoke([search_agent_prompt] + state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# === Specialized Content Agents ===\n",
    "def blog_agent(state: MessagesState):\n",
    "    prompt = SystemMessage(content=(\n",
    "        \"You are a professional **blog writer**. \"\n",
    "        \"Write an engaging, SEO-optimized blog post with:\\n\"\n",
    "        \"- A catchy title\\n\"\n",
    "        \"- Subheadings\\n\"\n",
    "        \"- Conversational tone\\n\"\n",
    "        \"- Conclusion\\n\"\n",
    "        \"Make it informative and easy to read.\"\n",
    "    ))\n",
    "    return {\"messages\": [llm.invoke([prompt] + state[\"messages\"])]}\n",
    "\n",
    "def article_agent(state: MessagesState):\n",
    "    prompt = SystemMessage(content=(\n",
    "        \"You are a **research-based article writer**. \"\n",
    "        \"Write a well-structured, factual, and formal article including:\\n\"\n",
    "        \"- Clear introduction\\n\"\n",
    "        \"- Supporting evidence and citations (if relevant)\\n\"\n",
    "        \"- Conclusion summarizing insights.\"\n",
    "    ))\n",
    "    return {\"messages\": [llm.invoke([prompt] + state[\"messages\"])]}\n",
    "\n",
    "def summary_agent(state: MessagesState):\n",
    "    prompt = SystemMessage(content=(\n",
    "        \"You are a **content summarizer**. \"\n",
    "        \"Summarize the provided topic into concise bullet points, highlighting the main facts and insights.\"\n",
    "    ))\n",
    "    return {\"messages\": [llm.invoke([prompt] + state[\"messages\"])]}\n",
    "\n",
    "def email_agent(state: MessagesState):\n",
    "    prompt = SystemMessage(content=(\n",
    "        \"You are an expert in **email communication**. \"\n",
    "        \"Write a professional, polite email draft addressing the given topic. \"\n",
    "        \"Use a clear subject line, a greeting, a concise message body, and a proper closing.\"\n",
    "    ))\n",
    "    return {\"messages\": [llm.invoke([prompt] + state[\"messages\"])]}\n",
    "\n",
    "def script_agent(state: MessagesState):\n",
    "    prompt = SystemMessage(content=(\n",
    "        \"You are a **scriptwriter**. \"\n",
    "        \"Create a short, engaging script suitable for a video or podcast. \"\n",
    "        \"Include intro, main talking points, and outro. \"\n",
    "        \"Keep it creative and natural in tone.\"\n",
    "    ))\n",
    "    return {\"messages\": [llm.invoke([prompt] + state[\"messages\"])]}\n",
    "\n",
    "def social_agent(state: MessagesState):\n",
    "    prompt = SystemMessage(content=(\n",
    "        \"You are a **social media expert**. \"\n",
    "        \"Write catchy, platform-appropriate social media content. \"\n",
    "        \"Include attention-grabbing hooks, hashtags, and a call to action.\"\n",
    "    ))\n",
    "    return {\"messages\": [llm.invoke([prompt] + state[\"messages\"])]}\n",
    "\n",
    "def general_agent(state: MessagesState):\n",
    "    prompt = SystemMessage(content=(\n",
    "        \"You are a helpful **AI content writer**. \"\n",
    "        \"Write a detailed and informative explanation of the topic provided.\"\n",
    "    ))\n",
    "    return {\"messages\": [llm.invoke([prompt] + state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# --- Define Tuning Agent ---\n",
    "tune_agent_prompt = SystemMessage(content=agent3_prompt)\n",
    "def tune_agent(state: MessagesState):\n",
    "    return {\"messages\": [llm.invoke([tune_agent_prompt] + state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# --- Helper Function: Decide Which Agent to Use ---\n",
    "def select_content_agent(state: MessagesState):\n",
    "    \"\"\"\n",
    "    Decide which content agent to use based on `content_type` in the user's message.\n",
    "    \"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    content_type = None\n",
    "\n",
    "    for msg in messages:\n",
    "        if isinstance(msg, HumanMessage) and isinstance(msg.content, dict):\n",
    "            content_type = msg.content.get(\"content_type\", \"\").lower()\n",
    "            break\n",
    "\n",
    "    mapping = {\n",
    "        \"blog\": \"blog_agent\",\n",
    "        \"article\": \"article_agent\",\n",
    "        \"summary\": \"summary_agent\",\n",
    "        \"email\": \"email_agent\",\n",
    "        \"script\": \"script_agent\",\n",
    "        \"social\": \"social_agent\",\n",
    "    }\n",
    "\n",
    "    return mapping.get(content_type, \"general_agent\")\n",
    "\n",
    "\n",
    "# --- Build Graph ---\n",
    "graph = StateGraph(MessagesState)\n",
    "graph.add_node(\"search_agent\", search_agent)\n",
    "graph.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "# Add specialized content agents\n",
    "graph.add_node(\"blog_agent\", blog_agent)\n",
    "graph.add_node(\"article_agent\", article_agent)\n",
    "graph.add_node(\"summary_agent\", summary_agent)\n",
    "graph.add_node(\"email_agent\", email_agent)\n",
    "graph.add_node(\"script_agent\", script_agent)\n",
    "graph.add_node(\"social_agent\", social_agent)\n",
    "graph.add_node(\"general_agent\", general_agent)\n",
    "graph.add_node(\"tune_agent\", tune_agent)\n",
    "\n",
    "# --- Graph Connections ---\n",
    "graph.add_edge(START, \"search_agent\")\n",
    "\n",
    "# Conditional path after search â†’ to tool or next content agent\n",
    "graph.add_conditional_edges(\"search_agent\", tools_condition, {\"tools\": \"tools\", \"__end__\": select_content_agent})\n",
    "graph.add_edge(\"tools\", \"search_agent\")\n",
    "\n",
    "# Content agents â†’ tuning â†’ END\n",
    "for node in [\"blog_agent\", \"article_agent\", \"summary_agent\", \"email_agent\", \"script_agent\", \"social_agent\", \"general_agent\"]:\n",
    "    graph.add_edge(node, \"tune_agent\")\n",
    "\n",
    "graph.add_edge(\"tune_agent\", END)\n",
    "\n",
    "# --- Compile Final Agent ---\n",
    "agent = graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc82ddae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from myagents.prompts import agent1_prompt, agent2_prompt, agent3_prompt\n",
    "\n",
    "\n",
    "# --- Initialize LLM ---\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "# llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "tools = [search_content]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# --- Define Agent 1: Search Agent ---\n",
    "search_agent_prompt = SystemMessage(content=agent1_prompt)\n",
    "def search_agent(state: MessagesState):\n",
    "    return {\"messages\": [llm_with_tools.invoke([search_agent_prompt] + state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# === Specialized Content Agents ===\n",
    "def blog_agent(state: MessagesState):\n",
    "    prompt = SystemMessage(content=f\"{agent2_prompt}\\n\\nInstruction: Write an engaging, SEO-friendly blog post.\")\n",
    "    return {\"messages\": [llm.invoke([prompt] + state[\"messages\"])]}\n",
    "\n",
    "def article_agent(state: MessagesState):\n",
    "    prompt = SystemMessage(content=f\"{agent2_prompt}\\n\\nInstruction: Write a well-researched, formal article.\")\n",
    "    return {\"messages\": [llm.invoke([prompt] + state[\"messages\"])]}\n",
    "\n",
    "def summary_agent(state: MessagesState):\n",
    "    prompt = SystemMessage(content=f\"{agent2_prompt}\\n\\nInstruction: Summarize the topic in concise bullet points.\")\n",
    "    return {\"messages\": [llm.invoke([prompt] + state[\"messages\"])]}\n",
    "\n",
    "def email_agent(state: MessagesState):\n",
    "    prompt = SystemMessage(content=f\"{agent2_prompt}\\n\\nInstruction: Write a professional email draft.\")\n",
    "    return {\"messages\": [llm.invoke([prompt] + state[\"messages\"])]}\n",
    "\n",
    "def script_agent(state: MessagesState):\n",
    "    prompt = SystemMessage(content=f\"{agent2_prompt}\\n\\nInstruction: Create a creative video or podcast script.\")\n",
    "    return {\"messages\": [llm.invoke([prompt] + state[\"messages\"])]}\n",
    "\n",
    "def social_agent(state: MessagesState):\n",
    "    prompt = SystemMessage(content=f\"{agent2_prompt}\\n\\nInstruction: Write a catchy social media caption or post.\")\n",
    "    return {\"messages\": [llm.invoke([prompt] + state[\"messages\"])]}\n",
    "\n",
    "def general_agent(state: MessagesState):\n",
    "    prompt = SystemMessage(content=f\"{agent2_prompt}\\n\\nInstruction: Write a detailed explanation.\")\n",
    "    return {\"messages\": [llm.invoke([prompt] + state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# --- Define Tuning Agent ---\n",
    "tune_agent_prompt = SystemMessage(content=agent3_prompt)\n",
    "def tune_agent(state: MessagesState):\n",
    "    return {\"messages\": [llm.invoke([tune_agent_prompt] + state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# --- Helper Function: Decide Which Agent to Use ---\n",
    "def select_content_agent(state: MessagesState):\n",
    "    \"\"\"\n",
    "    Decide which content agent to use based on `content_type` inside the user's message.\n",
    "    \"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    content_type = None\n",
    "\n",
    "    for msg in messages:\n",
    "        if isinstance(msg, HumanMessage) and isinstance(msg.content, dict):\n",
    "            content_type = msg.content.get(\"content_type\", \"\").lower()\n",
    "            break\n",
    "\n",
    "    mapping = {\n",
    "        \"blog\": \"blog_agent\",\n",
    "        \"article\": \"article_agent\",\n",
    "        \"summary\": \"summary_agent\",\n",
    "        \"email\": \"email_agent\",\n",
    "        \"script\": \"script_agent\",\n",
    "        \"social\": \"social_agent\",\n",
    "    }\n",
    "\n",
    "    # Default to general_agent if not found\n",
    "    return mapping.get(content_type, \"general_agent\")\n",
    "\n",
    "\n",
    "# --- Build Graph ---\n",
    "graph = StateGraph(MessagesState)\n",
    "graph.add_node(\"search_agent\", search_agent)\n",
    "graph.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "# Add all specialized content agents\n",
    "graph.add_node(\"blog_agent\", blog_agent)\n",
    "graph.add_node(\"article_agent\", article_agent)\n",
    "graph.add_node(\"summary_agent\", summary_agent)\n",
    "graph.add_node(\"email_agent\", email_agent)\n",
    "graph.add_node(\"script_agent\", script_agent)\n",
    "graph.add_node(\"social_agent\", social_agent)\n",
    "graph.add_node(\"general_agent\", general_agent)\n",
    "\n",
    "graph.add_node(\"tune_agent\", tune_agent)\n",
    "\n",
    "# --- Graph Connections ---\n",
    "graph.add_edge(START, \"search_agent\")\n",
    "\n",
    "# Conditional path after search\n",
    "graph.add_conditional_edges(\"search_agent\", tools_condition, {\"tools\": \"tools\", \"__end__\": select_content_agent})\n",
    "graph.add_edge(\"tools\", \"search_agent\")\n",
    "\n",
    "# After chosen content agent â†’ tuning â†’ END\n",
    "for node in [\"blog_agent\", \"article_agent\", \"summary_agent\", \"email_agent\", \"script_agent\", \"social_agent\", \"general_agent\"]:\n",
    "    graph.add_edge(node, \"tune_agent\")\n",
    "\n",
    "graph.add_edge(\"tune_agent\", END)\n",
    "\n",
    "# --- Compile Final Agent ---\n",
    "agent = graph.compile()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115c4a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "from typing import TypedDict, List\n",
    "from typing_extensions import Annotated\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, BaseMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from myagents.prompts import agent1_prompt, agent2_prompt, agent3_prompt\n",
    "\n",
    "\n",
    "\n",
    "from tools.search_tool import search_content\n",
    "\n",
    "# --- Define Custom Graph State ---\n",
    "# We use a custom state to store the content_type separately from the messages.\n",
    "class ContentWriterState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our multi-agent content writer.\n",
    "    Uses 'add_messages' reducer for the message history.\n",
    "    \"\"\"\n",
    "    messages: Annotated[List[BaseMessage], add_messages]\n",
    "    content_type: str # <-- NEW KEY for dynamic agent routing\n",
    "\n",
    "# --- Initialize LLM ---\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "tools = [search_content]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# --- Define Agent 1: Search Agent ---\n",
    "search_agent_prompt = SystemMessage(content=agent1_prompt)\n",
    "def search_agent(state: ContentWriterState):\n",
    "    # The search agent uses the tools-enabled LLM\n",
    "    return {\"messages\": [llm_with_tools.invoke([search_agent_prompt] + state[\"messages\"])]}\n",
    "\n",
    "# --- Define Agent 2: Content Agent (Dynamic by type) ---\n",
    "def content_agent(state: ContentWriterState):\n",
    "    \"\"\"\n",
    "    Dynamically adjusts the content generation style based on content_type \n",
    "    extracted directly from the state dictionary.\n",
    "    \"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # --- FIX: Extract content_type directly from the state ---\n",
    "    # This key was added in app.py when calling agent.invoke\n",
    "    content_type = state.get(\"content_type\", \"general\").lower()\n",
    "    \n",
    "    # Define dynamic content instructions\n",
    "    style_prompts = {\n",
    "        \"blog\": \"Write an engaging, SEO-friendly blog post about this topic. Include headings and structure.\",\n",
    "        \"article\": \"Write a well-researched, professional article with a formal tone.\",\n",
    "        \"summary\": \"Summarize the topic in concise, clear bullet points or short paragraphs.\",\n",
    "        \"email\": \"Write a professional email draft addressing this topic.\",\n",
    "        \"script\": \"Create a creative video or podcast script covering this topic.\",\n",
    "        \"social\": \"Write a short, catchy social media caption or post about this topic.\",\n",
    "    }\n",
    "\n",
    "    style_prompt = style_prompts.get(content_type, \"Write a detailed explanation about this topic.\")\n",
    "\n",
    "    # Combine system prompt dynamically (agent2_prompt sets the base persona)\n",
    "    dynamic_prompt = SystemMessage(content=f\"{agent2_prompt}\\n\\nInstruction: {style_prompt}\")\n",
    "\n",
    "    # Pass modified prompt and the *full* message history to LLM\n",
    "    return {\"messages\": [llm.invoke([dynamic_prompt] + messages)]}\n",
    "\n",
    "# --- Define Agent 3: Tuning Agent ---\n",
    "tune_agent_prompt = SystemMessage(content=agent3_prompt)\n",
    "def tune_agent(state: ContentWriterState):\n",
    "    return {\"messages\": [llm.invoke([tune_agent_prompt] + state[\"messages\"])]}\n",
    "\n",
    "# --- Build Graph ---\n",
    "# FIX: Use the custom state defined above\n",
    "graph = StateGraph(ContentWriterState) \n",
    "\n",
    "graph.add_node(\"search_agent\", search_agent)\n",
    "graph.add_node(\"tools\", ToolNode(tools))\n",
    "graph.add_node(\"content_agent\", content_agent)\n",
    "graph.add_node(\"tune_agent\", tune_agent)\n",
    "\n",
    "\n",
    "# --- Graph Connections ---\n",
    "graph.add_edge(START, \"search_agent\")\n",
    "\n",
    "# If search_agent calls tool, go to tools. If it's done (__end__), go to content_agent.\n",
    "graph.add_conditional_edges(\n",
    "    \"search_agent\",\n",
    "    tools_condition,\n",
    "    {\"tools\": \"tools\", \"__end__\": \"content_agent\"}\n",
    ")\n",
    "\n",
    "# After tools run (search results received) â†’ back to search_agent for next step\n",
    "graph.add_edge(\"tools\", \"search_agent\")\n",
    "\n",
    "# Removed redundant edge: graph.add_edge(\"search_agent\", \"content_agent\")\n",
    "\n",
    "graph.add_edge(\"content_agent\", \"tune_agent\")\n",
    "\n",
    "# tune Agent â†’ END\n",
    "graph.add_edge(\"tune_agent\", END)\n",
    "\n",
    "# --- Compile Agent ---\n",
    "agent = graph.compile()\n",
    "\n",
    "# # --- Run the flow ---\n",
    "mesg = HumanMessage(content=\"What is Adobe Experience Manager?\")\n",
    "result = agent.invoke({\"messages\": mesg})\n",
    "print(result[\"messages\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a28d3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from myagents.prompts import agent1_prompt,agent2_prompt,agent3_prompt\n",
    "from myagents.prompts import blog_agent_prompt, summary_agent_prompt, tutorial_agent_prompt, comparison_agent_prompt\n",
    "\n",
    "\n",
    "\n",
    "from tools.search_tool import search_content\n",
    "\n",
    "\n",
    "llm=ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "tools = [search_content]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "blog_agent_prompt_msg = SystemMessage(content=blog_agent_prompt)\n",
    "summary_agent_prompt_msg = SystemMessage(content=summary_agent_prompt)\n",
    "tutorial_agent_prompt_msg = SystemMessage(content=tutorial_agent_prompt)\n",
    "comparison_agent_prompt_msg = SystemMessage(content=comparison_agent_prompt)\n",
    "\n",
    "def blog_agent(state: MessagesState):\n",
    "    return {\"messages\": [llm.invoke([blog_agent_prompt_msg] + state[\"messages\"])]}\n",
    "\n",
    "def summary_agent(state: MessagesState):\n",
    "    return {\"messages\": [llm.invoke([summary_agent_prompt_msg] + state[\"messages\"])]}\n",
    "\n",
    "def tutorial_agent(state: MessagesState):\n",
    "    return {\"messages\": [llm.invoke([tutorial_agent_prompt_msg] + state[\"messages\"])]}\n",
    "\n",
    "def comparison_agent(state: MessagesState):\n",
    "    return {\"messages\": [llm.invoke([comparison_agent_prompt_msg] + state[\"messages\"])]}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "orchestrator_prompt = SystemMessage(\n",
    "    content=\"\"\"You are an orchestrator agent. \n",
    "Your job is to decide which content type best matches the user request. \n",
    "Possible content types are:\n",
    "- blog\n",
    "- summary\n",
    "- tutorial\n",
    "- comparison\n",
    "\n",
    "Return the name of the type that fits best (just one word: blog, summary, tutorial, or comparison).\"\"\"\n",
    ")\n",
    "\n",
    "def orchestrator_agent(state: MessagesState):\n",
    "    decision = llm.invoke([orchestrator_prompt] + state[\"messages\"])\n",
    "    decision_text = decision.content.strip().lower()\n",
    "\n",
    "    if \"blog\" in decision_text:\n",
    "        next_node = \"blog_agent\"\n",
    "    elif \"summary\" in decision_text:\n",
    "        next_node = \"summary_agent\"\n",
    "    elif \"tutorial\" in decision_text:\n",
    "        next_node = \"tutorial_agent\"\n",
    "    elif \"comparison\" in decision_text:\n",
    "        next_node = \"comparison_agent\"\n",
    "    else:\n",
    "        next_node = \"summary_agent\"  # default fallback\n",
    "\n",
    "    return {\"messages\": [decision], \"next_node\": next_node}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- Define Agent 1: Search Agent ---\n",
    "search_agent_prompt = SystemMessage(content=agent1_prompt)\n",
    "def search_agent(state: MessagesState):\n",
    "    return {\"messages\": [llm_with_tools.invoke([search_agent_prompt] + state[\"messages\"])]}\n",
    "\n",
    "# --- Define Agent 2: Content Agent ---\n",
    "content_agent_prompt = SystemMessage(content=agent2_prompt)\n",
    "def content_agent(state: MessagesState):\n",
    "    return {\"messages\": [llm.invoke([content_agent_prompt] + state[\"messages\"])]}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- Define Agent 3: Tuning Agent ---\n",
    "tune_agent_prompt = SystemMessage(content=agent3_prompt)\n",
    "def tune_agent(state: MessagesState):\n",
    "    return {\"messages\": [llm.invoke([tune_agent_prompt] + state[\"messages\"])]}\n",
    "\n",
    "# --- Build Graph ---\n",
    "graph = StateGraph(MessagesState)\n",
    "\n",
    "graph.add_node(\"search_agent\", search_agent)\n",
    "graph.add_node(\"tools\", ToolNode(tools))\n",
    "graph.add_node(\"orchestrator_agent\", orchestrator_agent)\n",
    "graph.add_node(\"blog_agent\", blog_agent)\n",
    "graph.add_node(\"summary_agent\", summary_agent)\n",
    "graph.add_node(\"tutorial_agent\", tutorial_agent)\n",
    "graph.add_node(\"comparison_agent\", comparison_agent)\n",
    "graph.add_node(\"tune_agent\", tune_agent)\n",
    "\n",
    "# Flow\n",
    "graph.add_edge(START, \"search_agent\")\n",
    "graph.add_conditional_edges(\n",
    "    \"search_agent\",\n",
    "    tools_condition,\n",
    "    {\"tools\": \"tools\", \"__end__\": \"orchestrator_agent\"}\n",
    ")\n",
    "graph.add_edge(\"tools\", \"search_agent\")\n",
    "\n",
    "# Orchestrator decides next path dynamically\n",
    "graph.add_conditional_edges(\n",
    "    \"orchestrator_agent\",\n",
    "    lambda state: state[\"next_node\"],\n",
    "    {\n",
    "        \"blog_agent\": \"blog_agent\",\n",
    "        \"summary_agent\": \"summary_agent\",\n",
    "        \"tutorial_agent\": \"tutorial_agent\",\n",
    "        \"comparison_agent\": \"comparison_agent\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# After content creation â†’ go to tune agent\n",
    "graph.add_edge(\"blog_agent\", \"tune_agent\")\n",
    "graph.add_edge(\"summary_agent\", \"tune_agent\")\n",
    "graph.add_edge(\"tutorial_agent\", \"tune_agent\")\n",
    "graph.add_edge(\"comparison_agent\", \"tune_agent\")\n",
    "\n",
    "graph.add_edge(\"tune_agent\", END)\n",
    "\n",
    "# --- Compile Agent ---\n",
    "agent = graph.compile()\n",
    "\n",
    "\n",
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcc2505",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d84478d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from agents.prompts import web_copy_prompt\n",
    "from agents.prompts import (\n",
    "    agent1_prompt,\n",
    "    agent2_prompt,\n",
    "    agent3_prompt,\n",
    "    thought_leadership_prompt,\n",
    "    web_copy_prompt,\n",
    "    email_sequence_prompt,\n",
    "    social_post_prompt,\n",
    "    sales_enablement_prompt,\n",
    "    blog_post_prompt\n",
    ")\n",
    "\n",
    "from tools.search_tool import search_content\n",
    "\n",
    "# --- Load environment variables ---\n",
    "load_dotenv()\n",
    "\n",
    "# --- Initialize LLM ---\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "# Alternative if you want to test with OpenAI:\n",
    "# llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "tools = [search_content]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# ============================================================\n",
    "# ðŸ§  DEFINE INDIVIDUAL CONTENT AGENTS\n",
    "# ============================================================\n",
    "\n",
    "def thought_leadership_agent(state: MessagesState):\n",
    "    return {\"messages\": [llm.invoke([SystemMessage(content=thought_leadership_prompt)] + state[\"messages\"])]}\n",
    "\n",
    "def web_copy_agent(state: MessagesState):\n",
    "    return {\"messages\": [llm.invoke([SystemMessage(content=web_copy_prompt)] + state[\"messages\"])]}\n",
    "\n",
    "def email_sequence_agent(state: MessagesState):\n",
    "    return {\"messages\": [llm.invoke([SystemMessage(content=email_sequence_prompt)] + state[\"messages\"])]}\n",
    "\n",
    "def social_post_agent(state: MessagesState):\n",
    "    return {\"messages\": [llm.invoke([SystemMessage(content=social_post_prompt)] + state[\"messages\"])]}\n",
    "\n",
    "def sales_enablement_agent(state: MessagesState):\n",
    "    return {\"messages\": [llm.invoke([SystemMessage(content=sales_enablement_prompt)] + state[\"messages\"])]}\n",
    "\n",
    "def blog_post_agent(state: MessagesState):\n",
    "    return {\"messages\": [llm.invoke([SystemMessage(content=blog_post_prompt)] + state[\"messages\"])]}\n",
    "\n",
    "# ============================================================\n",
    "# ðŸ§­ ORCHESTRATOR\n",
    "# ============================================================\n",
    "\n",
    "orchestrator_prompt = SystemMessage(content=\"\"\"\n",
    "You are an orchestrator agent.\n",
    "Your job is to decide which content type best fits the userâ€™s intent.\n",
    "Available content types:\n",
    "- thought_leadership\n",
    "- web_copy\n",
    "- email_sequence\n",
    "- social_post\n",
    "- sales_enablement\n",
    "- blog_post\n",
    "\n",
    "Return ONLY one keyword exactly matching the best type.\n",
    "\"\"\")\n",
    "\n",
    "def orchestrator_agent(state: MessagesState):\n",
    "    decision = llm.invoke([orchestrator_prompt] + state[\"messages\"])\n",
    "    decision_text = decision.content.strip().lower()\n",
    "\n",
    "    valid_types = [\n",
    "        \"thought_leadership\", \"web_copy\", \"email_sequence\",\n",
    "        \"social_post\", \"sales_enablement\", \"blog_post\"\n",
    "    ]\n",
    "    next_node = decision_text if decision_text in valid_types else \"blog_post\"  # fallback\n",
    "\n",
    "    print(f\"ðŸ§­ Orchestrator chose: {next_node}\")\n",
    "    return {\"messages\": [decision], \"next_node\": next_node}\n",
    "\n",
    "# ============================================================\n",
    "# ðŸ” SEARCH AGENT + TOOLS + TUNING AGENT\n",
    "# ============================================================\n",
    "\n",
    "search_agent_prompt = SystemMessage(content=agent1_prompt)\n",
    "def search_agent(state: MessagesState):\n",
    "    return {\"messages\": [llm_with_tools.invoke([search_agent_prompt] + state[\"messages\"])]}\n",
    "\n",
    "content_agent_prompt = SystemMessage(content=agent2_prompt)\n",
    "def content_agent(state: MessagesState):\n",
    "    return {\"messages\": [llm.invoke([content_agent_prompt] + state[\"messages\"])]}\n",
    "\n",
    "tune_agent_prompt = SystemMessage(content=agent3_prompt)\n",
    "def tune_agent(state: MessagesState):\n",
    "    return {\"messages\": [llm.invoke([tune_agent_prompt] + state[\"messages\"])]}\n",
    "\n",
    "# ============================================================\n",
    "# ðŸ•¸ï¸ BUILD THE GRAPH\n",
    "# ============================================================\n",
    "\n",
    "graph = StateGraph(MessagesState)\n",
    "\n",
    "# --- Add nodes ---\n",
    "graph.add_node(\"search_agent\", search_agent)\n",
    "graph.add_node(\"tools\", ToolNode(tools))\n",
    "graph.add_node(\"orchestrator_agent\", orchestrator_agent)\n",
    "graph.add_node(\"tune_agent\", tune_agent)\n",
    "\n",
    "# --- Add all content-type agents ---\n",
    "graph.add_node(\"thought_leadership\", thought_leadership_agent)\n",
    "graph.add_node(\"web_copy\", web_copy_agent)\n",
    "graph.add_node(\"email_sequence\", email_sequence_agent)\n",
    "graph.add_node(\"social_post\", social_post_agent)\n",
    "graph.add_node(\"sales_enablement\", sales_enablement_agent)\n",
    "graph.add_node(\"blog_post\", blog_post_agent)\n",
    "\n",
    "# --- Flow Setup ---\n",
    "graph.add_edge(START, \"search_agent\")\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"search_agent\",\n",
    "    tools_condition,\n",
    "    {\"tools\": \"tools\", \"__end__\": \"orchestrator_agent\"}\n",
    ")\n",
    "graph.add_edge(\"tools\", \"search_agent\")\n",
    "\n",
    "# Orchestrator â†’ correct agent\n",
    "graph.add_conditional_edges(\n",
    "    \"orchestrator_agent\",\n",
    "    lambda state: state[\"next_node\"],\n",
    "    {\n",
    "        \"thought_leadership\": \"thought_leadership\",\n",
    "        \"web_copy\": \"web_copy\",\n",
    "        \"email_sequence\": \"email_sequence\",\n",
    "        \"social_post\": \"social_post\",\n",
    "        \"sales_enablement\": \"sales_enablement\",\n",
    "        \"blog_post\": \"blog_post\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# After generation â†’ Tune â†’ END\n",
    "for node in [\"thought_leadership\", \"web_copy\", \"email_sequence\", \"social_post\", \"sales_enablement\", \"blog_post\"]:\n",
    "    graph.add_edge(node, \"tune_agent\")\n",
    "\n",
    "graph.add_edge(\"tune_agent\", END)\n",
    "\n",
    "# --- Compile the graph ---\n",
    "agent = graph.compile()\n",
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40df8141",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "-1.-1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
